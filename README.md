

# ðŸ›¡ï¸ SENTINEL â€” Secure Control Plane for Toolâ€‘Using AI Agents

![Sentinel Banner](docs/banner.png)

> **A productionâ€‘grade, agentâ€‘safety and toolâ€‘use control platform for autonomous AI systems â€” combining MCPâ€‘based tool isolation, LangGraph and FSM orchestration, GraphRAGâ€‘backed policy reasoning, and auditâ€‘grade decision traces. Designed to evaluate and enforce safe agent execution at scale.**

---

![Python](https://img.shields.io/badge/python-3.11-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-API-green)
![GraphQL](https://img.shields.io/badge/GraphQL-Control_Plane-purple)
![LangGraph](https://img.shields.io/badge/LangGraph-Orchestration-orange)
![FSM](https://img.shields.io/badge/Custom_FSM-Orchestration-lightgrey)
![MCP](https://img.shields.io/badge/MCP-Tool_Boundary-black)
![GraphRAG](https://img.shields.io/badge/GraphRAG-Policy_Reasoning-blue)
![Neo4j](https://img.shields.io/badge/Neo4j-Knowledge_Graph-brightgreen)
![Pinecone](https://img.shields.io/badge/Pinecone-Vector_Search-yellowgreen)
![Postgres](https://img.shields.io/badge/Postgres-Audit_DB-blue)
![Docker](https://img.shields.io/badge/Docker-Compose-blue)
![Status](https://img.shields.io/badge/status-active_development-orange)

---

â­ **Star this repository** â€” Sentinel is built as a reference system for safe, auditable agent execution.

---

## ðŸ”¥ Why Sentinel?

**Sentinel is not a chatbot, copilot, or demo agent.**  
It is a **control plane** for **toolâ€‘using AI agents**.

As modern LLM agents gain the ability to:
- read files
- query logs
- open tickets
- modify repositories
- interact with production systems

**prompt injection and unsafe tool execution become real security risks.**

Sentinel exists to answer a single hard question:

> *â€œShould this agent be allowed to do this â€” and can we prove why?â€*

---

## ðŸ§  About

Sentinel is an **agentâ€‘security research and engineering platform** built to:

- enforce **leastâ€‘privilege tool use**
- prevent **promptâ€‘injectionâ€‘driven actions**
- require **human approval for risky operations**
- produce **auditâ€‘grade reasoning traces**
- compare **LangGraph vs a Custom FSM** under identical safety constraints

It is **industryâ€‘agnostic** and applicable to:
- FAANGâ€‘scale internal tooling
- fintech, infra, and SRE platforms
- enterprise agent frameworks
- AI governance and security research

---

## ðŸ—ï¸ Core Concepts

Sentinel enforces strict separation of concerns:

| Layer | Responsibility |
|------|----------------|
| **Agent** | Proposes actions |
| **Gateway (Sentinel)** | Decides if actions are allowed |
| **MCP Server** | Executes tools (sandboxed) |
| **Policy Engine** | Enforces RBAC / ABAC |
| **GraphRAG** | Grounds decisions in policy and incidents |
| **Audit Store** | Persists every decision |
| **Evaluation Harness** | Compares orchestrators |

---

## âœ¨ Key Features

### ðŸ›¡ï¸ Agent Firewall (Control Plane)
- Intercepts **all agent tool calls**
- Enforces:
  - explicit allowlists
  - roleâ€‘based and environmentâ€‘based access
  - strict input validation
- Blocks unsafe execution **before tools are reached**

---

### ðŸ”Œ MCPâ€‘Based Tool Boundary
- All tools exposed via a **sandboxed MCP server**
- Readâ€‘only by default
- Write actions require explicit human approval
- No direct tool access from agents

This makes toolâ€‘use safety **concrete and enforceable**, not theoretical.

---

### ðŸ§  Dual Orchestration Engines
Sentinel evaluates the **same agent logic** across two orchestration strategies:

- **LangGraph**
- **Custom Finite State Machine (FSM)**

Everything else remains identical:
- LLM
- tools
- policies
- retrieval
- evaluation harness

This enables a **fair, reproducible comparison**.

---

### ðŸ“š GraphRAGâ€‘Backed Policy Reasoning
- Policies, incidents, and tool contracts stored in a **knowledge graph**
- Relevant subgraphs retrieved at decision time
- Decisions are grounded with:
  - policy citations
  - prior incident references
  - explicit reasoning paths

---

### ðŸ§¾ Auditâ€‘Grade Decision Traces
Every tool proposal produces a durable record:
- decision (ALLOW / BLOCK / APPROVAL_REQUIRED)
- rationale
- policy citations
- risk score
- redacted tool arguments
- timestamps

Nothing is implicit. Nothing is hidden.

---

### ðŸ“Š Evaluation & Leaderboards
Sentinel includes a builtâ€‘in evaluation harness to measure:

- promptâ€‘injection block rate
- unsafe execution rate
- falseâ€‘block rate
- task success rate
- latency
- tool calls per run

Results are compared across:
- LangGraph vs FSM
- different policy strictness profiles

---

## ðŸ§© System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agent   â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚ Proposes tool call
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Sentinel Gateway â”‚  (GraphQL)
â”‚  - Policy Engine â”‚
â”‚  - Risk Scoring  â”‚
â”‚  - GraphRAG      â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚ Allowed
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MCP Server   â”‚  (Sandboxed tools)
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â–¼
 Real / Mock Tools
```

---

## ðŸ”„ How It Works

1. A user or system submits a task  
2. The agent proposes one or more tool calls  
3. Sentinel evaluates:
   - tool permissions
   - role and environment
   - untrusted input boundaries
   - policy constraints
4. GraphRAG retrieves relevant policies and prior incidents  
5. A decision is made and persisted  
6. Approved calls are forwarded to the MCP server  
7. Tool outputs are redacted and returned  

---

## ðŸ—ƒï¸ Audit Database (Core Tables)

- **runs**
- **tool_calls**
- **decisions**
- **policy_citations**
- **metrics**

All schema changes are managed via Alembic migrations.

---

## ðŸ–¥ï¸ User Interfaces

Sentinel provides a web UI for **security, platform, and infra teams**:

### ðŸ” Dashboard
- active runs
- tool usage overview
- risk distribution

### ðŸ›‘ Approval Queue
- review pending write actions
- inspect diffs and intent
- approve or deny with justification

### ðŸ§¾ Decision Trace View
- full reasoning graph
- policy citations
- incident references

### ðŸ Leaderboard
- LangGraph vs FSM performance comparison
- safety vs utility tradeâ€‘offs

---

## ðŸ›£ï¸ Roadmap

### âœ… Phase 0 â€” System Spine
- Dockerized gateway and MCP server
- GraphQL control plane
- Audit logging
- Prometheus metrics

### ðŸš§ Phase 1 â€” Orchestration Comparison
- LangGraph runner
- Custom FSM runner
- Identical tool and policy interfaces

### ðŸš§ Phase 2 â€” GraphRAG Proof Mode
- Neo4j policy graph
- Incident grounding
- Decision explanation graphs

### ðŸš§ Phase 3 â€” Evaluation Harness
- Promptâ€‘injection test suite
- Leaderboards
- Regression safety tests

---

## ðŸ“Œ Status

**Active development. Designed as a reference architecture for safe agent execution.**

---

## ðŸ¤ Why This Project Matters

Sentinel targets one of the most urgent unsolved problems in modern AI systems:

> *How do we safely allow autonomous agents to act in the real world?*

This repository answers that question with **engineering rigor, explicit safety boundaries, and measurable evaluation** â€” not demos.
